% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nlcm_doubletree.R
\name{nlcm_doubletree}
\alias{nlcm_doubletree}
\title{wrapper function for fitting and summaries}
\usage{
nlcm_doubletree(
  Y,
  leaf_ids,
  mytrees,
  weighted_edges = c(TRUE, TRUE),
  ci_level = 0.95,
  get_lcm_by_group = FALSE,
  update_hyper_freq = 50,
  print_freq = 10,
  quiet = FALSE,
  plot_fig = FALSE,
  hyper_fixed = list(K = 2, LD = FALSE),
  tol = 1e-08,
  tol_hyper = 1e-04,
  max_iter = 5000,
  nrestarts = 3,
  keep_restarts = TRUE,
  parallel = TRUE,
  log_restarts = FALSE,
  log_dir = ".",
  vi_params_init = list(),
  hyperparams_init = list(),
  random_init = FALSE,
  random_init_vals = list(mu_gamma_sd_frac = 0.2, mu_alpha_sd_frac = 0.2, tau1_lims =
    c(0.5, 1.5), tau2_lims = c(0.5, 1.5), u_sd_frac = 0.2, psi_sd_frac = 0.2, phi_sd_frac
    = 0.2),
  allow_continue = FALSE
)
}
\arguments{
\item{Y}{\code{N} by \code{J} binary data matrix; rows for subjects,
columns for features; missing entries, if present, are encoded by \code{NA}s. Note
that the rows of \code{Y} will be reordered twice, once according to leaf nodes/missing
in tree1, the second time according to the leaf nodes in tree2.}

\item{leaf_ids}{A list containing two elements. For example,
the first can be a vector of character strings for leaf
nodes for each observation, representing the leaf nodes
in \code{tree1}; similarly for the second tree; \code{NA} represents for missing leaf info.
For each observation, the pair of labels indicates
the leaf memberships in the two trees contained in \code{mytrees}, respectively.
For example, in verbal autopsy (VA) applications, for data in the source domains,
we must have both leaf ids observed; for data in the target domain, we can have the leaf id
in the first tree (i.e., cause tree) \code{NA}, indicating an unobserved cause
of death (hence unknown to analysts which leaf in the cause tree should an
observation be placed). In this package, we only allow \code{NA} for leaf labels in tree1;
tree2's leaves represent domains, which must be known when doing domain adaptation.
Currently the \code{NA} in tree1, if present, can only contain ALL subjects from a single leaf node
in tree2. NB: Extensions to deal with CODs that are partially observed in the
target domain need additional work...}

\item{mytrees}{A list of two elements: \code{tree1},\code{tree2}; both are
\code{igraph} objects. They may contain attributes, such as node, edge, edge lengths.
(NB: need refinement)}

\item{weighted_edges}{a vector of logical values, indicating whether to use weighted
edges in the two trees; default to \code{c(FALSE,FALSE)}, i.e., not using weighted edges
and assuming the edges in the trees are unit lengths.}

\item{ci_level}{A number between 0 and 1 giving the desired credible interval.
For example, \code{ci_level = 0.95} (the default) returns a 95\% credible interval}

\item{get_lcm_by_group}{If \code{TRUE}, \code{doubletree} will also return the maximum likelihood estimates of the
coefficients for each leaf_ids group discovered by the model.
Default is \code{TRUE}.}

\item{update_hyper_freq}{How frequently to update hyperparameters.
Default = every 50 iterations.}

\item{print_freq}{How often to print out iteration number and current value of epsilon
(the difference in objective function value for the two most recent iterations).}

\item{quiet}{default to \code{FALSE}, which prints empirical class probabilities and updates on
tau's}

\item{plot_fig}{plot figure about \code{prob} (the probability of each node diffuse from
the parent node, i.e., s_u=1 for using the slab component) and response profile (1st node)}

\item{hyper_fixed}{Fixed values of hyperprior parameters.}

\item{tol}{Convergence tolerance for the objective function.
Default is \code{1E-8}.}

\item{tol_hyper}{The convergence tolerance for the objective function
between subsequent hyperparameter updates. Typically it is a more generous
tolerance than \code{tol}. Default is \code{1E-4}.}

\item{max_iter}{Maximum number of iterations of the VI algorithm.
Default is \code{5000}. NB: check this number before package submission.}

\item{nrestarts}{Number of random re-starts of the VI algorithm.
The restart that gives the highest value of the objective function will
be returned. It is recommended to choose \code{nrestarts > 1}; The default is \code{3}.}

\item{keep_restarts}{If \code{TRUE}, the results from all random restarts
will be returned. If \code{FALSE}, only the restart with the highest objective function is returned. '
Default is \code{TRUE}.}

\item{parallel}{If \code{TRUE}, the random restarts will be run in parallel.
It is recommended to first set the number of cores using \code{doParallel::registerDoParallel()}.
Otherwise, the default number of cores specified by the \code{doParallel} package will be used.
Default is \code{TRUE}.}

\item{log_restarts}{If \code{TRUE}, when \code{nrestarts > 1} progress of each random
restart will be logged to a text file in \code{log_dir}. If \code{FALSE} and \code{nrestarts > 1},
progress will not be shown.
If \code{nrestarts = 1}, progress will always be printed to the console.
Default is \code{FALSE}.}

\item{log_dir}{Directory for logging progress of random restarts.
Default is the working directory.}

\item{vi_params_init, hyperparams_init}{Named lists containing initial values for the
variational parameters and hyperparameters. Supplying good initial values can be challenging,
and \code{lotR()} provides a way to guess initial values based on transformations
of latent class model estimates for each individual leaf_ids (see \code{\link[=initialize_tree_lcm]{initialize_tree_lcm()}}).
The most common use for \code{vi_params_init} and \code{hyperparams_init} is to supply starting
values based on previous output from \code{lotR()};
see the \code{vignette('lotR')} for examples.
The user can provide initial values for all parameters or a subset.
When initial values for one or more parameters are not
supplied, the missing values will be filled in by \code{\link[=initialize_nlcm_doubletree]{initialize_nlcm_doubletree()}}.}

\item{random_init}{If \code{TRUE}, some random variability will be added to the initial values.
The default is \code{FALSE}, unless \code{nrestarts > 1}, in which case
\code{random_init} will be set to \code{TRUE} and a warning message will be printed.
The amount of variability is determined by \code{random_init_vals}.}

\item{random_init_vals}{If \code{random_init = TRUE},
this is a list containing the following parameters for randomly permuting
the initial values.
NB: The following are copied from lotR; so need edits!!!!!!!
\describe{
\item{\code{tau_lims}}{a vector of length \code{2}, where \code{tau_lims[1]} is between \code{0} and \code{1},
and \code{tau_lims[2] > 1}. The initial values for the hyperparameter \code{tau} will
be chosen uniformly at random in the range \verb{(tau_init * tau_lims[1], tau_init * tau_lims[2])},
where \code{tau_init} is the initial value for \code{tau} either supplied in \code{hyperparams_init}
or guessed using \code{\link[=initialize_nlcm_doubletree]{initialize_nlcm_doubletree()}}.}
\item{\code{psi_sd_frac}}{a value between \code{0} and \code{1}. The initial values for the auxiliary parameters
\code{psi} will have a normal random variate added to them with standard deviation equal to
\code{psi_sd_frac} multiplied by the initial value for eta either supplied in \code{hyperparams_init} or guessed
using \code{\link[=initialize_nlcm_doubletree]{initialize_nlcm_doubletree()}}. Absolute values are then taken for any
values of \code{psi} that are \verb{< 0}.}
\item{\code{phi_sd_frac}}{same as above}.
\item{\code{mu_gamma_sd_frac}}{a value between 0 and 1. The initial values for
\code{mu} will have a normal random variate added to them with standard deviation equal to
\code{mu_sd_frac} multiplied by the absolute value of the initial value for \code{mu_gamma_sd_frac} either supplied in
\code{vi_params_init} or guessed using \code{\link[=initialize_nlcm_doubletree]{initialize_nlcm_doubletree()}}.}
\item{\code{mu_alpha_sd_frac}}{same as above.}
\item{\code{u_sd_frac}}{a value between 0 and 1. The initial value for the node inclusion probabilities
will first be transformed to the log odds scale to obtain \code{u}. A normal random variate will be
added to \code{u} with standard deviation equal to u_sd_frac multiplied by the absolute value of the
initial value for \code{u} either supplied in \code{vi_params_init} or guessed using \code{moretrees_init_logistic()}.
\code{u} will then be transformed back to the probability scale.}
}}

\item{allow_continue}{logical, \code{TRUE} to save results so can continue running the VI
updates with the last iteration from the old results.}
}
\value{
a list also of class "nlcm_doubletree"; NB: need to create a simulated example that uses this function!

\describe{
res <- make_list(mod,mod_restarts,mytrees,dsgn,prob_est,est_ad_hoc)
class(res) <- c("nlcm_doubletree","list")
}
}
\description{
wrapper function for fitting and summaries
}
\examples{
rm(list=ls())
library(igraph)
library(doubletree)
library(MASS)
library(poLCA)
library(BayesLCA)

# second tree - over domains:
data("example_domain_edges")
domain_tree <- graph_from_edgelist(example_domain_edges, directed = TRUE)

igraph::V(domain_tree)$levels <- rep(1,length(igraph::V(domain_tree)))
igraph::E(domain_tree)$weight <- rep(1,length(E(domain_tree)))

nodes2  <- names(igraph::V(domain_tree))
leaves2 <- names(igraph::V(domain_tree)[igraph::degree(domain_tree, mode = "out") == 0])
rootnode2 <- names(igraph::V(domain_tree)[igraph::degree(domain_tree, mode = "in") == 0])
pL2 <- length(leaves2)
p2  <- length(nodes2)
V(domain_tree)$levels <- rep(1,p2)
E(domain_tree)$weight <- rep(1,length(E(domain_tree)))

# first tree - over causes:
data("example_cause_edges")
#cause_tree <- graph_from_edgelist(example_cause_edges, directed = TRUE)
cause_tree <- domain_tree

igraph::V(cause_tree)$levels <- rep(1,length(igraph::V(cause_tree)))
igraph::E(cause_tree)$weight <- rep(1,length(E(cause_tree)))

nodes1  <- names(igraph::V(cause_tree))
leaves1 <- names(igraph::V(cause_tree)[igraph::degree(cause_tree, mode = "out") == 0])
rootnode1 <- names(igraph::V(cause_tree)[igraph::degree(cause_tree, mode = "in") == 0])
pL1 <- length(leaves1)
p1  <- length(nodes1)
# set the levels l*_u for nodes in the cause tree; nodes
# in the same level will share a slab variance multiplier tau_l* (times the edge length
# eminating from the parent).
V(cause_tree)$levels <- rep(1,p1) # this is to set every node to the same level.
E(cause_tree)$weight <- rep(1,length(E(cause_tree))) # set equal edge lengths of 1.


mytrees <- list(tree1 = cause_tree, tree2 = domain_tree)
###############################################################################
## Begin simulating data using the two trees above.
###############################################################################
n     <- 1000
K     <- 2
J     <- 18 # J =168 in the data

fracs_leaves1 <- c(1,rep(1,pL1-1))
fracs_leavs1  <- fracs_leaves1/sum(fracs_leaves1)
pi_mat        <- matrix(fracs_leaves1,nrow=pL1,ncol=pL2)

# create tree1 leaf level class-specific response probabilities:
itemprob0 <- rbind(rep(rep(c(0.95, 0.95), each = 1),9),
                   rep(rep(c(0.1, 0.1), each = 1),9)) # not used if K=1.
gamma_mat_list <- list(logit(itemprob0))

for (u in 1:(p1-1)){ # random increments on random columns
  increment_mat <- matrix(rnorm(J*K,0,1),nrow=K,ncol=J)
  ind_j         <- sample(1:J,floor(J/2))
  increment_mat[,ind_j] <- 0
  gamma_mat_list <- append(gamma_mat_list,list(increment_mat))
}
# matrix(rnorm(J*K,0,0.5),nrow=K,ncol=J),
# matrix(rnorm(J*K,0,0.5),nrow=K,ncol=J)),
# rep(list(matrix(0,nrow=K,ncol=J)),p1-3))


# matrix for each of the pL1 leaves in tree1.
#########################################################################
## diffusion along tree1 for itemprob_list
#########################################################################

# get lists of ancestors for each leaf_ids:
d1 <- igraph::diameter(mytrees[[1]],weights=NA)
# need to set weight=NA to prevent the use of edge lengths in determining the diameter.
ancestors1 <- igraph::ego(mytrees[[1]], order = d1 + 1, nodes = leaves1, mode = "in")
ancestors1 <- sapply(ancestors1, names, simplify = FALSE)
ancestors1 <- sapply(ancestors1, function(a, nodes) which(nodes \%in\% a),
                     nodes = nodes1, simplify = FALSE)
names(ancestors1) <- leaves1
# the list of item response probability
itemprob_list <-list()
for (v1 in 1:pL1){
  curr_mat <- itemprob0
  ind_j <- sample(1:J,floor(J/2))
  for (j in ind_j){
    curr_mat[,j] <- itemprob0[rev(1:nrow(curr_mat)),j]
  }
  # itemprob_list[[v1]] <- expit(Reduce("+",gamma_mat_list[ancestors1[[v1]]]))
  itemprob_list[[v1]] <- curr_mat
}

par(mfrow=c(ceiling(sqrt(pL1+1)),ceiling(sqrt(pL1+1))),
    mar=c(1,1,1,1))
for (v1 in 1:pL1){
  image(itemprob_list[[v1]],main=v1)
}

# get lists of ancestors for each leaf_ids:
d2 <- igraph::diameter(mytrees[[2]],weights=NA)
# need to set weight=NA to prevent the use of edge lengths in determining the diameter.
ancestors2 <- igraph::ego(mytrees[[2]], order = d2 + 1, nodes = leaves2, mode = "in")
ancestors2 <- sapply(ancestors2, names, simplify = FALSE)
ancestors2 <- sapply(ancestors2, function(a, nodes) which(nodes \%in\% a),
                     nodes = nodes2, simplify = FALSE)
names(ancestors2) <- leaves2

# calculate the class probabilities for all leaf nodes in tree2; each leaf node
# should have a K-dim vector that sums to one; Some nodes may share
# the same set of K-dim probability vector, others may differ. There are
# one or more groups of leaf nodes with distinct K-dim probability vectors.
# Note the branch lengths may also be used here.
lambda_mat_list <- list() # will be a list of length pL1, each being K by pL2.
for (v1 in 1:pL1){
  lambda_mat_list[[v1]] <- matrix(NA,nrow=K,ncol=pL2)
  for (v2 in 1:pL2){
    lambda_mat_list[[v1]][,v2] <- c(1,0) # although K=2, but only the first response profile is used.
  }
}

# s = c(1,1,1,0,0, rep(0,pL)) # effective nodes
example_data_doubletree <- simulate_nlcm_doubletree(n,mytrees,itemprob_list,lambda_mat_list,pi_mat)
print("counts in simulation:")
example_data_doubletree$N_sim_mat
# save the simulated data to the R package for illustration:
# save(example_data_doubletree, file = "data/example_data_doubletree.rda", compress = "xz

# FITTING MODELS:
curr_leaf_ids <- vector("list",2)
curr_leaf_ids[[1]] <- leaves1[example_data_doubletree$truth$true_leaf_ids[,1]]
#curr_leaf_ids[[1]][1:10] <- NA
curr_leaf_ids[[1]][example_data_doubletree$truth$true_leaf_ids[,2]==1] <- NA # <--- make this work.
curr_leaf_ids[[2]] <- leaves2[example_data_doubletree$truth$true_leaf_ids[,2]]

mod <- nlcm_doubletree(
  example_data_doubletree$Y,curr_leaf_ids,
  example_data_doubletree$truth$mytrees,weighted_edges = c(FALSE,FALSE),
  ci_level = 0.95,
  get_lcm_by_group = FALSE,
  update_hyper_freq = 20,
  print_freq = 20,
  quiet      = FALSE,
  plot_fig   = FALSE, # <-- used?
  tol        = 1E-8,
  tol_hyper = 1E-4,
  max_iter = 1000,
  nrestarts = 1,
  keep_restarts = TRUE,
  parallel = TRUE,
  log_restarts = FALSE,
  log_dir = ".",
  vi_params_init = list(),
  hyperparams_init = list(),
  random_init = FALSE,
  random_init_vals = list(mu_gamma_sd_frac = 0.2,
                          mu_alpha_sd_frac = 0.2,
                          tau1_lims = c(0.5,1.5),
                          tau2_lims = c(0.5,1.5),
                          u_sd_frac = 0.2, # for logit of probs
                          psi_sd_frac = 0.2,
                          phi_sd_frac = 0.2),
  hyper_fixed = list(K=2,LD=TRUE, # number of latent classes.
                     a1 = rep(20,max(igraph::V(cause_tree)$levels)),
                     b1 = rep(1,max(igraph::V(cause_tree)$levels)),
                     a2=matrix(1,nrow=length(ancestors1),ncol=max(igraph::V(domain_tree)$levels)),
                     # <-- NB: where do we specify levels? in the tree.
                     b2=matrix(10,nrow=length(ancestors1),ncol=max(igraph::V(domain_tree)$levels)),
                     # both (a1,b1),(a2,b2) can encourage shrinkage towards the parent.
                     dmat = matrix(1,nrow=length(ancestors1),ncol=length(ancestors2)), # (cause,domain).
                     #s1_u_zeroset = c(2:p1), # force NO diffusion in tree1.
                     s1_u_zeroset = NULL, # not force diffusion in tree1.
                     #s1_u_oneset = 1,    # not force diffusion in tree1.
                     s1_u_oneset = 1:p1,  # force diffusion in tree1.
                     #s2_cu_zeroset = rep(list(2:p2),pL1), # force NO diffusion in non-roots tree2.
                     s2_cu_zeroset = NULL,            # not force diffusion in tree2.
                     s2_cu_oneset = rep(list(1),pL1), # not force diffusion in tree2.
                     #s2_cu_oneset = rep(list(1:p2),pL1), # force diffusion tree2.
                     tau_update_levels = list(1,1)
  )
)

# get the design output; this is needed because the function reorders the data rows:
dsgn0 <- design_doubletree(example_data_doubletree$Y,curr_leaf_ids,
                           example_data_doubletree$truth$mytrees)

# for each tree1 leaf, look at shrinkage structure across tree2:
par(mfrow=c(ceiling(sqrt(pL1+1)),ceiling(sqrt(pL1+1))),
    mar=c(1,1,1,1))
for (u in 1:pL1){
  plot(mod$mod$vi_params$prob2[[u]],type="h",ylim=c(0,1));abline(h=0.5)
}
# look at shrinkage structure across tree1:
plot(mod$mod$vi_params$prob1,type="h",ylim=c(0,1),col="blue");abline(h=0.5)

do.call("rbind",mod$mod$vi_params$prob2)

heatmap(mod$mod$vi_params$emat[is.na(dsgn0$leaf_ids[[1]]),],Rowv=NA,Colv=NA)
# heatmap(mod$mod$vi_params$emat[!is.na(dsgn0$leaf_ids[[1]]),],Rowv=NA,Colv=NA)
# heatmap(mod$mod$vi_params$emat,Rowv=NA,Colv=NA)

# posterior means of CSMFs:
sweep(mod$mod$vi_params$dirich_mat,MARGIN = 2,colSums(mod$mod$vi_params$dirich_mat),"/")

# visualize tree2 root node class probabilities for each tree1 leaf; can change to
# nodes other than tree2 root node:
heatmap(apply(mod$mod$vi_params$mu_alpha[[1]],1,function(v) tsb(c(expit(v),1))),Rowv=NA,Colv=NA)
apply(mod$mod$vi_params$mu_alpha[[1]],1,function(v) tsb(c(expit(v),1)))

#
# CLASSIFICATION:
#
# MAP cause assignment:
xx <- mod$mod$vi_params$emat[is.na(dsgn0$leaf_ids[[1]]),]
apply(xx,1,which.max)

# true causes:
na_index <- which(is.na(dsgn0$leaf_ids[[1]]))
example_data_doubletree$truth$true_leaf_ids[dsgn0$all_ord[na_index],1]


# domains of the observations missing tree1 leaf label:
truth <- example_data_doubletree$truth$true_leaf_ids[dsgn0$all_ord[na_index],1]
map_nlcm <- apply(xx,1,which.max)

table(map_nlcm,truth)
sum(map_nlcm!=truth)/length(map_nlcm)

#
# RESPONSE PROBABILITIES:
#
itemprob_list_est <-list()
for (v1 in 1:pL1){
  itemprob_list_est[[v1]] <- t(expit(Reduce("+",mod$mod$vi_params$mu_gamma[ancestors1[[v1]]])))
}

par(mfrow=c(ceiling(sqrt(pL1+1)),ceiling(sqrt(pL1+1))),
    mar=c(1,1,1,1))
for (v1 in 1:pL1){
  image(itemprob_list_est[[v1]],main=v1)
}

#
# LATENT CLASS PROBABILITIES:
#
heatmap(mod$mod$vi_params$rmat,Rowv=NA,Colv=NA)

# how do we avoid tree1 leaf specific class relabeling. perhaps need to consider the same set of alphas
# no matter which tree1 leaf it is.

## need to confirm the classification performance; here we have very collapsed
## tree for the causes, so the classification performance likely would not be great.





}
\concept{nlcm_doubletree functions}
